import os
from torch.utils.data import DataLoader
import torch
import mlflow
import numpy as np
import copy

from pytorcher.trainer.pytorch_trainer import PytorchTrainer
from noise2noise.data.data_loader import SinogramGeneratorReconstructionTest
from pet_recon.castor_reconstructor import CastorPetReconstruction
from tools.image.metrics import PSNR


class InferencePipeline(PytorchTrainer):
    
    """
    This pipeline performs the reconstruction task from sinograms on a test dataset.
    The sinograms are first denoised using a trained Noise2Noise model, then reconstructed using MLEM/OSEM.
    Metrics are computed between the reconstructed images and the ground truth images.
    """

    def __init__(self, model_name, model_version, metrics_configs=[],
                image_size=(256,256), voxel_size=(2,2,2), dataset_size=128, batch_size=1,
                dest_path='./', seed=42, binsimu=None, binrecon=None, num_workers=4):
        self.image_size = image_size
        self.voxel_size = voxel_size
        self.dataset_size = dataset_size
        self.batch_size = batch_size
        self.dest_path = dest_path
        self.seed = seed
        self.binrecon = binrecon if binrecon is not None else f"{os.getenv('WORKSPACE')}/castor_v3.2_bin/castor-recon_unix64"
        self.binsimu = binsimu if binsimu is not None else f"{os.getenv('WORKSPACE')}/simulator/bin"
        self.num_workers = num_workers
        #
        self.device = self.get_device()
        #
        self.model = self.get_model(model_name, model_version, device=self.device)
        #
        # add prefix for noisy reconstruction and denoised reconstruction metrics
        metrics_configs_ = []
        for metric_config in metrics_configs:
            metric_name = metric_config[0]
            metric_params = copy.deepcopy(metric_config[1])
            metric_params.update({'name': f'denoised_recon_{metric_name}'})
            metrics_configs_.append([metric_name, metric_params])
            metric_params = copy.deepcopy(metric_config[1])
            metric_params.update({'name': f'noisy_recon_{metric_name}'})
            metrics_configs_.append([metric_name, metric_params])

        self.metrics = self.get_metrics(metrics_configs_)
        # remove loss
        self.metrics = [m for m in self.metrics if m.name != 'loss']
        #
        self.reconstructor = self.get_reconstructor()
        #
        self.data_loader_test = self.create_test_data_loader()

    def get_reconstructor(self):
        self.reconstructor = CastorPetReconstruction(
            binrecon=self.binrecon,
            binsimu=self.binsimu,
            fout="recon",
            verbose=1
        )
        return self.reconstructor

    def get_model(self, model_name, model_version, device):
        """
        Load registered model from MLflow.
        """
        model_uri = f"models:/{model_name}/{model_version}"
        self.model = mlflow.pytorch.load_model(model_uri=model_uri, device=device)
        print(f"Loaded model '{model_name}' version {model_version} from MLflow.")
        return self.model

    def create_test_data_loader(self):
        """
        Create test data loader.
        """
        self.dataset_test = SinogramGeneratorReconstructionTest(self.binsimu,
                                         dest_path=os.path.join(self.dest_path),
                                         length=self.dataset_size,
                                         image_size=self.image_size,
                                         voxel_size=self.voxel_size,
                                         seed=self.seed)
        loader_test = DataLoader(self.dataset_test, batch_size=self.batch_size, shuffle=False, num_workers=self.num_workers)
        return loader_test

    def run(self):

        def reconstruct_batch_image(dest_path, sinogram, is_sinogram_denoised):
            reconstructed_images = []

            for i in range(self.batch_size):

                # add channel dimension for reconstructor
                sinogram_i = sinogram[i].unsqueeze(-1)
                # save denoised sinogram to file for reconstruction
                # the current prompt sinogram generated by the simulation process will be overwritten
                # This file is not used anyway as we compute poisson noise from the noise-free sinogram
                with open(f'{dest_path[i]}/simu/simu_pt.s', 'wb') as f:
                    # ensure a CPU numpy array in little-endian 16-bit signed format and contiguous memory
                    arr = sinogram_i.numpy().astype('<i2')
                    f.write(arr.tobytes())
                    
                # reconstruct denoised sinogram
                if is_sinogram_denoised:
                    dest_path_recon = f"{dest_path[i]}/recon_denoised"
                else:
                    dest_path_recon = f"{dest_path[i]}/recon_noisy"
                iterations = 16
                subsets = 16

                self.reconstructor.run(dest_path_recon, it=f"{iterations}:{subsets}", dim=(*self.image_size,1), voxel_size=self.voxel_size)

                # read reconstructed image
                PSNRs = []
                out = None
                max_PSNR = 0.0
                for it in range(1,iterations+1):
                    with open(f'{dest_path_recon}/recon_it{it}.img', 'rb') as f:
                        # Get reconstructed image for current iteration
                        recon_image = torch.frombuffer(f.read(), dtype=torch.float32)
                        recon_image = recon_image.reshape(self.image_size)
                        # Compute PSNR between reconstructed image and image ground truth
                        PSNRs.append(PSNR(object_ground_truth.select(0, i).numpy(), recon_image))
                        # update result
                        if out is None or PSNRs[-1] > max_PSNR:
                            out = recon_image
                            max_PSNR = PSNRs[-1]

                # add image to batch
                reconstructed_images.append(out)

            reconstructed_images = torch.stack(reconstructed_images)
            return reconstructed_images

        self.reset_metrics()

        for batch_idx, (dest_path, noisy_sinogram, _, object_ground_truth) in enumerate(self.data_loader_test):

            print(f'Processing batch {batch_idx+1}/{len(self.data_loader_test)}')

            self.model.eval()
            with torch.no_grad():
                # denoise with N2N model
                noisy_sinogram = noisy_sinogram.to(self.device)
                if noisy_sinogram.dim() == 3:
                    noisy_sinogram = noisy_sinogram.unsqueeze(1)  # add channel dimension
                denoised_sinogram = self.model(noisy_sinogram)
                denoised_sinogram = denoised_sinogram.cpu()

            # remove channel dimension
            denoised_sinogram = denoised_sinogram.squeeze(1)
            #
            # cast as 16-bit signed integer for reconstruction
            denoised_sinogram = denoised_sinogram.clamp(min=0).round().to(torch.int16)
            # reconstruct images
            reconstructed_images_denoised = reconstruct_batch_image(dest_path, denoised_sinogram.cpu(), is_sinogram_denoised=True)
            reconstructed_images_noisy = reconstruct_batch_image(dest_path, noisy_sinogram.cpu(), is_sinogram_denoised=False)

            # compute metrics
            for metric in self.metrics:
                if 'noisy_recon_' in metric.name:
                    metric.update_state(normalize_batch(object_ground_truth), normalize_batch(reconstructed_images_noisy))
                elif 'denoised_recon_' in metric.name:
                    metric.update_state(normalize_batch(object_ground_truth), normalize_batch(reconstructed_images_denoised))

        # log metrics
        for metric in self.metrics:
            print(f'Test {metric.name} on reconstructed images: {metric.result()}')

if __name__ == "__main__":

    mlflow.set_tracking_uri(os.getenv("MLFLOW_TRACKING_URI"))


    inference_pipeline = InferencePipeline(
        model_name="Noise2Noise_2DPET_Model",
        model_version=10,
        metrics_configs=[
            ['PSNR', {}],
            ['SSIM', {}]
        ],
        image_size=(256,256),
        voxel_size=(2,2,2),
        dataset_size=1,
        batch_size=1,
        dest_path=f"{os.getenv('WORKSPACE')}/data/noise2noise/test",
        seed=42,
        binsimu=f"{os.getenv('WORKSPACE')}/simulator/bin",
        num_workers=10
    )

    inference_pipeline.run()